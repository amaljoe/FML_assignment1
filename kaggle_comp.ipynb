{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:29.955530Z",
     "start_time": "2024-08-24T14:44:29.950133Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.f2py.crackfortran import verbose\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ],
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:31.936695Z",
     "start_time": "2024-08-24T14:44:31.636342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('iitb-cs-725-1-2024/train.csv')\n",
    "test = pd.read_csv('iitb-cs-725-1-2024/test.csv')\n",
    "sample = pd.read_csv('iitb-cs-725-1-2024/sample.csv')"
   ],
   "id": "e22c4fd90e032e7a",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:38.571018Z",
     "start_time": "2024-08-24T14:44:38.552554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create datasets\n",
    "def create_datasets(data):\n",
    "    X = data.drop(['score', 'ID'], axis=1)\n",
    "    y = data['score']\n",
    "    X = np.array(X)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "# Shuffle the data\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n_train = int(0.9 * train.shape[0])\n",
    "X_train, y_train = create_datasets(train[:n_train])\n",
    "X_val, y_val = create_datasets(train[n_train:])\n",
    "\n",
    "X_train.shape, X_val.shape"
   ],
   "id": "51514d8dfadf7680",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31489, 64), (3499, 64))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:40.236313Z",
     "start_time": "2024-08-24T14:44:40.227620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def predict(X, W):\n",
    "    return X @ W\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "# def rmse(y_true, y_pred):\n",
    "#     return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def compute_gradients(X, y, y_pred):\n",
    "    dW = -2 * X.T @ (y - y_pred) / X.shape[0]\n",
    "    return dW\n",
    "\n",
    "def fit(X, y, W, Xval, yval, lr=0.01, epochs=100, print_every=100, batch_size=32):\n",
    "    # Error list\n",
    "    errors = []\n",
    "    val_errors = []\n",
    "    best_val_error = float('inf')\n",
    "    best_W = None\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Mini-batch gradient descent\n",
    "        idx = random.sample(range(X.shape[0]), batch_size)\n",
    "        X_batch, y_batch = X[idx], y[idx]\n",
    "        y_pred = predict(X_batch, W)\n",
    "\n",
    "        if i % print_every == 0 or i == epochs - 1:\n",
    "            train_loss = mse(y, predict(X, W))\n",
    "            y_val_pred = predict(Xval, W)\n",
    "            val_loss = mse(yval, y_val_pred)\n",
    "            Y_val_round = y_val_pred.round()\n",
    "            Y_val_rounded_loss = mse(yval, Y_val_round)\n",
    "            print(f'Epoch {i}, Loss: {train_loss}, Val Loss: {val_loss}, Rounded Val Loss: {Y_val_rounded_loss}')\n",
    "            errors.append(train_loss)\n",
    "            val_errors.append(val_loss)\n",
    "            if val_loss < best_val_error:\n",
    "                best_val_error = val_loss\n",
    "                best_W = W\n",
    "            if train_loss < 0.8 and val_loss < 0.87:\n",
    "                print(f'Early stopping at epoch {i}, Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "                break\n",
    "\n",
    "        dW = compute_gradients(X_batch, y_batch, y_pred)\n",
    "        W -= lr * dW\n",
    "\n",
    "    return best_W, errors, val_errors"
   ],
   "id": "c180fbdca030deee",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T12:20:47.842247Z",
     "start_time": "2024-08-24T12:20:47.807622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Closed form solution\n",
    "\n",
    "from closedForm import LinearRegressionClosedForm\n",
    "\n",
    "model = LinearRegressionClosedForm()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "rmse(y_val, y_pred)"
   ],
   "id": "4c91e943fbd0d643",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2682933059181574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:44.546088Z",
     "start_time": "2024-08-24T14:44:44.542991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_errors(errors, val_errors):\n",
    "    plt.plot(errors, label='Train')\n",
    "    plt.plot(val_errors, label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "b5a34a0664c55127",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:45.647765Z",
     "start_time": "2024-08-24T14:44:45.528601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature engineering\n",
    "\n",
    "# Mean and variance\n",
    "mu = np.mean(X_train)\n",
    "sigma = np.std(X_train)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def gaussian_basis(x, mu, sigma):\n",
    "    return np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "def normalize(X, mu, sigma):\n",
    "    return (X - mu) / sigma\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Add polynomial features\n",
    "def transform_input(X):\n",
    "    mu = np.mean(X)\n",
    "    sigma = np.std(X)\n",
    "    X_new = X\n",
    "    for i in range(-3, 3):\n",
    "        j = i / 3\n",
    "        X_new = np.hstack([X_new, gaussian_basis(X, mu + j, sigma)])\n",
    "    return X_new\n",
    "        \n",
    "\n",
    "X_train_poly = transform_input(X_train)\n",
    "X_val_poly = transform_input(X_val)\n",
    "print(X_train_poly.shape, X_val_poly.shape)\n",
    "\n",
    "W_poly = np.random.randn(X_train_poly.shape[1], 1)"
   ],
   "id": "486672be6ba5336c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 448) (3499, 448)\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:48.919322Z",
     "start_time": "2024-08-24T14:44:48.915102Z"
    }
   },
   "cell_type": "code",
   "source": "W_poly = np.load('weights7.npy')",
   "id": "88eca1d4ebe01ada",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:44:50.454093Z",
     "start_time": "2024-08-24T14:44:49.953054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 100\n",
    "\n",
    "W_train_poly, errors, val_errors = fit(X_train_poly, y_train, W_poly, X_val_poly, y_val, lr=0.0001, epochs=epochs, print_every=epochs/10, batch_size=256)\n",
    "\n",
    "plot_errors(errors, val_errors)\n",
    "\n",
    "y_pred = predict(X_val_poly, W_train_poly)\n",
    "y_pred_round = y_pred.round()\n",
    "mse(y_val, y_pred_round)"
   ],
   "id": "ed943654e030999e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8839812691116103, Val Loss: 0.9078282018259176, Rounded Val Loss: 0.9925693055158616\n",
      "Epoch 10, Loss: 0.8839516714224172, Val Loss: 0.9078782713216447, Rounded Val Loss: 0.9925693055158616\n",
      "Epoch 20, Loss: 0.8838556733451101, Val Loss: 0.9081857412919296, Rounded Val Loss: 0.9908545298656759\n",
      "Epoch 30, Loss: 0.8839248058454348, Val Loss: 0.9079321125058829, Rounded Val Loss: 0.9931408973992569\n",
      "Epoch 40, Loss: 0.8839118580834734, Val Loss: 0.9079653363639579, Rounded Val Loss: 0.992283509574164\n",
      "Epoch 50, Loss: 0.88384441748772, Val Loss: 0.9086226644513307, Rounded Val Loss: 0.9917119176907688\n",
      "Epoch 60, Loss: 0.8838430994336773, Val Loss: 0.9085265416442356, Rounded Val Loss: 0.9911403258073735\n",
      "Epoch 70, Loss: 0.8838548258269058, Val Loss: 0.9087292597555454, Rounded Val Loss: 0.9882823663903972\n",
      "Epoch 80, Loss: 0.8838397573796521, Val Loss: 0.9084414635171818, Rounded Val Loss: 0.9919977136324665\n",
      "Epoch 90, Loss: 0.8838407738906419, Val Loss: 0.9083631019136509, Rounded Val Loss: 0.9905687339239783\n",
      "Epoch 99, Loss: 0.8838619900084408, Val Loss: 0.9081667638108389, Rounded Val Loss: 0.9908545298656759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9905687339239783"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:30:53.187829Z",
     "start_time": "2024-08-24T14:30:53.185159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# export weights\n",
    "np.save('weights8.npy', W_train_poly)\n",
    "W_backup = W_train_poly"
   ],
   "id": "bc4407bfda51ec3f",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:30:55.645185Z",
     "start_time": "2024-08-24T14:30:55.576407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_val_poly = transform_input(X_val)\n",
    "y_pred = predict(X_val_poly, W_poly)\n",
    "y_pred_round = y_pred.round()\n",
    "\n",
    "mse(y_val, y_pred_round)"
   ],
   "id": "2aea3318c3e290d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448413832523578"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:31:48.672402Z",
     "start_time": "2024-08-24T14:31:48.515936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get output for final test data\n",
    "X_final_test = np.array(test.drop('ID', axis=1))\n",
    "X_final_test_poly = transform_input(X_final_test)\n",
    "y_final_test = predict(X_final_test_poly, W_poly)\n",
    "y_final_test = y_final_test.round()\n",
    "\n",
    "output = pd.DataFrame({'ID': test['ID'], 'score': y_final_test.flatten()})\n",
    "\n",
    "output['score'] = output['score'].clip(0, 5)\n",
    "\n",
    "# count score < 0\n",
    "below0 = output[output['score'] < 0].shape[0]\n",
    "\n",
    "# count score > 5\n",
    "above5 = output[output['score'] > 5].shape[0]\n",
    "\n",
    "print(output.shape[0], below0, above5)\n",
    "\n",
    "output.to_csv('output8.csv', index=False)"
   ],
   "id": "6a41c6871d40ef33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14996 0 0\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T14:32:34.057727Z",
     "start_time": "2024-08-24T14:32:34.047973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compare output7 and output8\n",
    "output7 = pd.read_csv('output7.csv')\n",
    "output8 = pd.read_csv('output8.csv')\n",
    "\n",
    "(output7['score'] == output8['score']).sum()"
   ],
   "id": "8a88eae870e6d233",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14996"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:19:37.799872Z",
     "start_time": "2024-08-23T06:19:27.643080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def gaussian_basis(x):\n",
    "    # Mean and variance\n",
    "    mu = np.mean(x)\n",
    "    sigma = np.std(x)\n",
    "    return np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "def normalize(X):\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Add polynomial features\n",
    "def transform_input(X, basis):\n",
    "    transormed_X = np.hstack([basis[i](X) for i in range(len(basis))])\n",
    "    transormed_X = np.hstack([X, transormed_X])\n",
    "    return transormed_X\n",
    "\n",
    "basis_funcs = [\n",
    "    [normalize],\n",
    "    [gaussian_basis],\n",
    "    [sigmoid],\n",
    "    [sigmoid, gaussian_basis, normalize],\n",
    "]\n",
    "\n",
    "for basis in basis_funcs:\n",
    "    transformed_X_train = transform_input(X_train, basis)\n",
    "    transformed_X_val = transform_input(X_val, basis)\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(transformed_X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    model.fit(transformed_X_train, y_train, validation_data=(transformed_X_val, y_val), epochs=10, verbose=0)\n",
    "    train_loss, val_loss = model.evaluate(transformed_X_train, y_train), model.evaluate(transformed_X_val, y_val)\n",
    "    print(basis, train_loss, val_loss)"
   ],
   "id": "f1d0246721ba13c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187us/step - loss: 0.8705\n",
      "\u001B[1m110/110\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 206us/step - loss: 0.8961\n",
      "[<function normalize at 0x38ef3daf0>] 0.8870629668235779 0.8694994449615479\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188us/step - loss: 0.8607\n",
      "\u001B[1m110/110\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 211us/step - loss: 0.8802\n",
      "[<function gaussian_basis at 0x3b3d63550>] 0.8777105212211609 0.8520484566688538\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189us/step - loss: 0.8657\n",
      "\u001B[1m110/110\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 221us/step - loss: 0.8883\n",
      "[<function sigmoid at 0x38375dee0>] 0.882866621017456 0.8620593547821045\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189us/step - loss: 0.8679\n",
      "\u001B[1m110/110\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 210us/step - loss: 0.8938\n",
      "[<function sigmoid at 0x38375dee0>, <function gaussian_basis at 0x3b3d63550>, <function normalize at 0x38ef3daf0>] 0.8849837779998779 0.8647343516349792\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T05:50:12.135187Z",
     "start_time": "2024-08-23T05:50:09.230259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "model.fit(transformed_X_train, y_train, validation_data=(transformed_X_val, y_val), epochs=10)"
   ],
   "id": "2b47c33d566cd0ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 349us/step - loss: 1.3638 - val_loss: 1.0372\n",
      "Epoch 2/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 0.9448 - val_loss: 0.9532\n",
      "Epoch 3/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - loss: 0.9095 - val_loss: 0.9712\n",
      "Epoch 4/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 291us/step - loss: 0.8788 - val_loss: 0.9324\n",
      "Epoch 5/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 290us/step - loss: 0.8806 - val_loss: 0.8915\n",
      "Epoch 6/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 289us/step - loss: 0.8550 - val_loss: 0.9437\n",
      "Epoch 7/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - loss: 0.8317 - val_loss: 0.8486\n",
      "Epoch 8/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 292us/step - loss: 0.8230 - val_loss: 0.8512\n",
      "Epoch 9/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - loss: 0.8435 - val_loss: 0.8431\n",
      "Epoch 10/10\n",
      "\u001B[1m875/875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - loss: 0.8142 - val_loss: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x381fb0f70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T07:12:49.563119Z",
     "start_time": "2024-08-23T07:12:49.532866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Add polynomial features\n",
    "def transform_input(X, basis):\n",
    "    transormed_X = np.hstack([basis[i](X) for i in range(len(basis))])\n",
    "    transormed_X = np.hstack([X, transormed_X])\n",
    "    return transormed_X\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def gaussian_basis(x):\n",
    "    # Mean and variance\n",
    "    mu = np.mean(x)\n",
    "    sigma = np.std(x)\n",
    "    return np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "basis = [gaussian_basis]\n",
    "\n",
    "transformed_X_train = transform_input(X_train, basis)\n",
    "transformed_X_val = transform_input(X_val, basis)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(transformed_X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "id": "b0ae2f862bc0269d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_111\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_111\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_134 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m129\u001B[0m (516.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> (516.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m129\u001B[0m (516.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> (516.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T07:13:32.103994Z",
     "start_time": "2024-08-23T07:13:05.310034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "model.fit(transformed_X_train, y_train, validation_data=(transformed_X_val, y_val), epochs=100)"
   ],
   "id": "72800032e3ad2466",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 344us/step - loss: 3.3207 - val_loss: 1.4445\n",
      "Epoch 2/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 256us/step - loss: 1.3784 - val_loss: 1.3350\n",
      "Epoch 3/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 253us/step - loss: 1.2782 - val_loss: 1.2485\n",
      "Epoch 4/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 253us/step - loss: 1.2242 - val_loss: 1.1806\n",
      "Epoch 5/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 248us/step - loss: 1.1312 - val_loss: 1.1279\n",
      "Epoch 6/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 253us/step - loss: 1.0916 - val_loss: 1.0818\n",
      "Epoch 7/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 248us/step - loss: 1.0511 - val_loss: 1.0465\n",
      "Epoch 8/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 252us/step - loss: 1.0085 - val_loss: 1.0163\n",
      "Epoch 9/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 254us/step - loss: 0.9937 - val_loss: 0.9920\n",
      "Epoch 10/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.9806 - val_loss: 0.9714\n",
      "Epoch 11/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.9652 - val_loss: 0.9547\n",
      "Epoch 12/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.9458 - val_loss: 0.9405\n",
      "Epoch 13/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.9507 - val_loss: 0.9318\n",
      "Epoch 14/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 268us/step - loss: 0.9287 - val_loss: 0.9219\n",
      "Epoch 15/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.9134 - val_loss: 0.9119\n",
      "Epoch 16/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 267us/step - loss: 0.9074 - val_loss: 0.9056\n",
      "Epoch 17/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.9017 - val_loss: 0.8995\n",
      "Epoch 18/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.9041 - val_loss: 0.8954\n",
      "Epoch 19/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.9011 - val_loss: 0.8911\n",
      "Epoch 20/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8922 - val_loss: 0.8877\n",
      "Epoch 21/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8963 - val_loss: 0.8861\n",
      "Epoch 22/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 272us/step - loss: 0.8979 - val_loss: 0.8822\n",
      "Epoch 23/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8853 - val_loss: 0.8811\n",
      "Epoch 24/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8810 - val_loss: 0.8791\n",
      "Epoch 25/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8789 - val_loss: 0.8770\n",
      "Epoch 26/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.9060 - val_loss: 0.8762\n",
      "Epoch 27/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8769 - val_loss: 0.8758\n",
      "Epoch 28/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8884 - val_loss: 0.8745\n",
      "Epoch 29/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 271us/step - loss: 0.8828 - val_loss: 0.8731\n",
      "Epoch 30/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8784 - val_loss: 0.8726\n",
      "Epoch 31/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8863 - val_loss: 0.8718\n",
      "Epoch 32/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8894 - val_loss: 0.8721\n",
      "Epoch 33/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8856 - val_loss: 0.8709\n",
      "Epoch 34/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8702 - val_loss: 0.8702\n",
      "Epoch 35/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 263us/step - loss: 0.8668 - val_loss: 0.8705\n",
      "Epoch 36/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8770 - val_loss: 0.8696\n",
      "Epoch 37/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 263us/step - loss: 0.8893 - val_loss: 0.8697\n",
      "Epoch 38/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8903 - val_loss: 0.8696\n",
      "Epoch 39/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8714 - val_loss: 0.8701\n",
      "Epoch 40/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8941 - val_loss: 0.8689\n",
      "Epoch 41/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8711 - val_loss: 0.8685\n",
      "Epoch 42/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8936 - val_loss: 0.8684\n",
      "Epoch 43/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 263us/step - loss: 0.8632 - val_loss: 0.8685\n",
      "Epoch 44/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8699 - val_loss: 0.8682\n",
      "Epoch 45/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8823 - val_loss: 0.8687\n",
      "Epoch 46/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 256us/step - loss: 0.8813 - val_loss: 0.8691\n",
      "Epoch 47/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8703 - val_loss: 0.8682\n",
      "Epoch 48/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8692 - val_loss: 0.8677\n",
      "Epoch 49/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8730 - val_loss: 0.8678\n",
      "Epoch 50/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8783 - val_loss: 0.8677\n",
      "Epoch 51/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8776 - val_loss: 0.8691\n",
      "Epoch 52/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8719 - val_loss: 0.8681\n",
      "Epoch 53/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8642 - val_loss: 0.8678\n",
      "Epoch 54/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8787 - val_loss: 0.8679\n",
      "Epoch 55/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8862 - val_loss: 0.8676\n",
      "Epoch 56/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8719 - val_loss: 0.8674\n",
      "Epoch 57/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 256us/step - loss: 0.8867 - val_loss: 0.8690\n",
      "Epoch 58/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8762 - val_loss: 0.8673\n",
      "Epoch 59/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8781 - val_loss: 0.8677\n",
      "Epoch 60/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8645 - val_loss: 0.8710\n",
      "Epoch 61/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8807 - val_loss: 0.8680\n",
      "Epoch 62/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 263us/step - loss: 0.8786 - val_loss: 0.8674\n",
      "Epoch 63/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8830 - val_loss: 0.8675\n",
      "Epoch 64/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8762 - val_loss: 0.8675\n",
      "Epoch 65/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8861 - val_loss: 0.8674\n",
      "Epoch 66/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8792 - val_loss: 0.8670\n",
      "Epoch 67/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8819 - val_loss: 0.8677\n",
      "Epoch 68/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8704 - val_loss: 0.8668\n",
      "Epoch 69/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8904 - val_loss: 0.8671\n",
      "Epoch 70/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8776 - val_loss: 0.8676\n",
      "Epoch 71/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8804 - val_loss: 0.8676\n",
      "Epoch 72/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8665 - val_loss: 0.8667\n",
      "Epoch 73/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 262us/step - loss: 0.8711 - val_loss: 0.8668\n",
      "Epoch 74/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8688 - val_loss: 0.8667\n",
      "Epoch 75/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8703 - val_loss: 0.8689\n",
      "Epoch 76/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 256us/step - loss: 0.8811 - val_loss: 0.8668\n",
      "Epoch 77/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 266us/step - loss: 0.8867 - val_loss: 0.8671\n",
      "Epoch 78/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 268us/step - loss: 0.8764 - val_loss: 0.8672\n",
      "Epoch 79/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8724 - val_loss: 0.8683\n",
      "Epoch 80/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 271us/step - loss: 0.8842 - val_loss: 0.8680\n",
      "Epoch 81/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 270us/step - loss: 0.8747 - val_loss: 0.8670\n",
      "Epoch 82/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 265us/step - loss: 0.8720 - val_loss: 0.8665\n",
      "Epoch 83/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 267us/step - loss: 0.8739 - val_loss: 0.8667\n",
      "Epoch 84/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 271us/step - loss: 0.8828 - val_loss: 0.8671\n",
      "Epoch 85/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 261us/step - loss: 0.8790 - val_loss: 0.8669\n",
      "Epoch 86/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8601 - val_loss: 0.8685\n",
      "Epoch 87/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8786 - val_loss: 0.8683\n",
      "Epoch 88/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8759 - val_loss: 0.8667\n",
      "Epoch 89/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8769 - val_loss: 0.8667\n",
      "Epoch 90/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 259us/step - loss: 0.8788 - val_loss: 0.8666\n",
      "Epoch 91/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 257us/step - loss: 0.8724 - val_loss: 0.8667\n",
      "Epoch 92/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8815 - val_loss: 0.8667\n",
      "Epoch 93/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258us/step - loss: 0.8773 - val_loss: 0.8664\n",
      "Epoch 94/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 264us/step - loss: 0.8775 - val_loss: 0.8664\n",
      "Epoch 95/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 260us/step - loss: 0.8723 - val_loss: 0.8664\n",
      "Epoch 96/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 272us/step - loss: 0.8813 - val_loss: 0.8665\n",
      "Epoch 97/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 268us/step - loss: 0.8668 - val_loss: 0.8684\n",
      "Epoch 98/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 270us/step - loss: 0.8848 - val_loss: 0.8666\n",
      "Epoch 99/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 271us/step - loss: 0.8650 - val_loss: 0.8664\n",
      "Epoch 100/100\n",
      "\u001B[1m985/985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 267us/step - loss: 0.8644 - val_loss: 0.8665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3b21817c0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T07:13:35.042685Z",
     "start_time": "2024-08-23T07:13:34.974191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RMSE\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "rmse.update_state(y_val, model.predict(transformed_X_val))\n",
    "rmse.result().numpy()"
   ],
   "id": "d6195f3c11d05e9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m110/110\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 248us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93085057"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 216
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "0.92 current best rmse on val set submitted\n",
    "0.87 ideally should be the best rmse on val set"
   ],
   "id": "17cadff8693a8a59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ec6cb201d3ede94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
